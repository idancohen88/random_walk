{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PURE_PYTHON=True\n"
     ]
    }
   ],
   "source": [
    "%env PURE_PYTHON True\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from BTrees.OOBTree import OOBTree\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import timeit\n",
    "\n",
    "CHUNKS_SIZE = 10000\n",
    "KEY_LENGTH = 8\n",
    "ALPHABET = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_debug_random_sampling = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DEFAULT_EXPLORING_STEP = 0\n",
    "os.environ[\"PURE_PYTHON\"] = \"True\"\n",
    "\n",
    "from BTrees.OOBTree import OOBTree as _OOBTree\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class OOBTreeExtLean(_OOBTree):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(OOBTreeExtLean, self).__init__()\n",
    "        self.walking_path_to_fanout_distribution = {}\n",
    "        self.default_exploring_step = DEFAULT_EXPLORING_STEP\n",
    "\n",
    "    def random_sampling(self, k):\n",
    "        self._first_walk_to_determine_structure()\n",
    "        self.walking_path_to_fanout_distribution = {}\n",
    "        all_accept_reject_measures = {\n",
    "            'accept': [],\n",
    "            'reject': [],\n",
    "            'revisited_paths': Counter()\n",
    "        }\n",
    "\n",
    "        k = min(len(self), k)\n",
    "        sampled_values = []\n",
    "        all_walking_paths_set = set()\n",
    "        all_walking_paths_stats = []\n",
    "        while len(sampled_values) < k:\n",
    "            sampled_value, walking_path, walking_path_stats  = \\\n",
    "                self._get_value_and_path_by_random_walk_from_node(node=self)\n",
    "\n",
    "            if _this_value_was_sampled_already(walking_path, all_walking_paths_set):\n",
    "                all_accept_reject_measures['revisited_paths'][str(walking_path)] += 1\n",
    "                continue\n",
    "\n",
    "            accept_reject_measures = {\n",
    "                'path': walking_path,\n",
    "                'value': sampled_value,\n",
    "            }\n",
    "\n",
    "            all_accept_reject_measures['accept'].append(accept_reject_measures)\n",
    "\n",
    "            all_walking_paths_set.add(str(walking_path))\n",
    "            all_walking_paths_stats.append(walking_path_stats)\n",
    "            sampled_values.append(sampled_value)\n",
    "\n",
    "        add_to_debug_global(locals())\n",
    "\n",
    "        return sampled_values\n",
    "\n",
    "    def _walk_to_determine_prob(self, node, forcing_step):\n",
    "        if isinstance(node._data[0].child, self._bucket_type):\n",
    "            next_step = self.default_exploring_step\n",
    "            fanout = len(node._data)\n",
    "            chosen_random_step_prob = 1 / fanout\n",
    "            fraction = f\"{1}/{fanout}\"\n",
    "        else:\n",
    "            all_sizes = np.array([node.child.size for node in node._data])\n",
    "            node_distribution = all_sizes / sum(all_sizes)\n",
    "            next_step = forcing_step if forcing_step is not None else self.default_exploring_step\n",
    "            fraction = f\"{all_sizes[next_step]}/{sum(all_sizes)}\"\n",
    "            chosen_random_step_prob = node_distribution[next_step]\n",
    "\n",
    "        return next_step, chosen_random_step_prob, fraction\n",
    "\n",
    "    def _first_walk_to_determine_structure(self):\n",
    "        root = self\n",
    "        tree_probs = {}\n",
    "        for i in range(len(root._data)):\n",
    "            current_node = root\n",
    "            prob_to_bucket = 1\n",
    "            walking_path_stats = []\n",
    "            while not isinstance(current_node, self._bucket_type):\n",
    "                force_step = current_node == root\n",
    "                next_step, step_prob, fraction = self._walk_to_determine_prob(current_node, forcing_step=i if force_step else None)\n",
    "                # assert next_step == 0, 'walking always on 0 just to determine structure'\n",
    "                prob_to_bucket *= step_prob\n",
    "\n",
    "                current_node = current_node._data[next_step].child\n",
    "\n",
    "                walking_path_stats.append({\n",
    "                    'next_random_step': next_step,\n",
    "                    'chosen_random_step_prob': step_prob,\n",
    "                    'prob_along_path': prob_to_bucket,\n",
    "                    'fraction': fraction\n",
    "                        })\n",
    "            tree_probs[i] = walking_path_stats\n",
    "\n",
    "        all_sizes = np.array([node.child.size for node in root._data])\n",
    "        node_distribution = np.array(all_sizes / sum(all_sizes))\n",
    "\n",
    "        branch_coefs = np.array([x[-1]['prob_along_path'] for x in tree_probs.values()])\n",
    "\n",
    "        gaus = np.zeros((len(branch_coefs) + 1, len(branch_coefs)))\n",
    "\n",
    "        for i in range(len(branch_coefs)):\n",
    "            gaus[i][0] = branch_coefs[0]\n",
    "            gaus[i][i] = -1 * branch_coefs[i]\n",
    "            gaus[-1][i] = node_distribution[i]\n",
    "\n",
    "        gaus_eq = np.zeros(len(branch_coefs))\n",
    "        gaus_eq[-1] = 1\n",
    "\n",
    "        x = np.linalg.solve(gaus[1:,], gaus_eq)\n",
    "\n",
    "        self.root_probs_coefs = np.linalg.solve(gaus[1:,], gaus_eq)\n",
    "\n",
    "    def _get_value_and_path_by_random_walk_from_node(self, node):\n",
    "        walking_path = []\n",
    "        current_node = node\n",
    "        prob_along_path = 1\n",
    "        walking_path_stats = []\n",
    "        while not isinstance(current_node, self._bucket_type):\n",
    "            root = not walking_path_stats\n",
    "            if root:\n",
    "                next_random_step, chosen_random_step_prob = self._random_next_move_respect_fanout_prob_from_root(\n",
    "                    current_node, walking_path)\n",
    "            else:\n",
    "                next_random_step, chosen_random_step_prob = self._random_next_move_respect_fanout_prob(current_node, walking_path)\n",
    "            prob_along_path *= chosen_random_step_prob\n",
    "            walking_path.append((next_random_step, current_node.size, chosen_random_step_prob, prob_along_path))\n",
    "            current_node = current_node._data[next_random_step].child\n",
    "            walking_path_stats.append({\n",
    "                'next_random_step': next_random_step,\n",
    "                'chosen_random_step_prob':\n",
    "                    chosen_random_step_prob, 'prob_along_path':prob_along_path})\n",
    "\n",
    "        next_random_step = np.random.randint(low=0, high=current_node.size)\n",
    "        chosen_random_step_prob = 1/current_node.max_leaf_size  # todo: size\n",
    "        prob_along_path *= chosen_random_step_prob\n",
    "        walking_path.append((next_random_step, current_node.size, chosen_random_step_prob, prob_along_path))\n",
    "        walking_path_stats.append({\n",
    "            'next_random_step': next_random_step,\n",
    "            'chosen_random_step_prob':\n",
    "                chosen_random_step_prob, 'prob_along_path': prob_along_path,\n",
    "            'entire_walking_path': walking_path})\n",
    "\n",
    "        leaf = current_node._keys\n",
    "        return leaf[next_random_step], walking_path, walking_path_stats\n",
    "\n",
    "\n",
    "    def _random_next_move_respect_fanout_prob(self, current_node, walking_path):\n",
    "        walking_path_str = str(walking_path)\n",
    "        if walking_path_str in self.walking_path_to_fanout_distribution:\n",
    "            node_distribution = self.walking_path_to_fanout_distribution[walking_path_str]\n",
    "        else:\n",
    "            all_sizes = np.array([node.child.size for node in current_node._data])\n",
    "            node_distribution = all_sizes / sum(all_sizes)\n",
    "            self.walking_path_to_fanout_distribution[walking_path_str] = node_distribution\n",
    "\n",
    "        next_random_step = np.random.choice(current_node.size, p=node_distribution)\n",
    "        chosen_random_step_prob = node_distribution[next_random_step]\n",
    "        return next_random_step, chosen_random_step_prob\n",
    "\n",
    "    def _random_next_move_respect_fanout_prob_from_root(self, current_node, walking_path):\n",
    "        walking_path_str = str(walking_path)\n",
    "        if walking_path_str in self.walking_path_to_fanout_distribution:\n",
    "            node_distribution = self.walking_path_to_fanout_distribution[walking_path_str]\n",
    "        else:\n",
    "            all_sizes = np.array([node.child.size for node in current_node._data])\n",
    "            node_distribution = np.array(all_sizes / sum(all_sizes))\n",
    "            node_distribution *= self.root_probs_coefs\n",
    "            #node_distribution = node_distribution / sum(node_distribution)\n",
    "            self.walking_path_to_fanout_distribution[walking_path_str] = node_distribution\n",
    "        next_random_step = np.random.choice(current_node.size, p=node_distribution)\n",
    "        chosen_random_step_prob = node_distribution[next_random_step]\n",
    "        return next_random_step, chosen_random_step_prob\n",
    "\n",
    "\n",
    "    def join(self, right_tree):\n",
    "        pass\n",
    "\n",
    "\n",
    "def add_to_debug_global(all_vars):\n",
    "    global _debug_random_sampling\n",
    "    _debug_random_sampling.append({\n",
    "        'params': {\n",
    "            'k': all_vars['k'],\n",
    "        },\n",
    "        'tree_size': len(all_vars['self']),\n",
    "        'all_accept_reject_measures': all_vars['all_accept_reject_measures'],\n",
    "        'all_walking_paths_stats': all_vars['all_walking_paths_stats']\n",
    "    })\n",
    "\n",
    "\n",
    "def _this_value_was_sampled_already(walking_path, all_walking_paths_set):\n",
    "    return str(walking_path) in all_walking_paths_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_btree_index_x_values_with_dist(num_of_values, disired_prefix_to_percent_dist, my_index=None):\n",
    "    my_index = my_index if my_index is not None else OOBTreeExt()\n",
    "    for prefix, amount_percent in disired_prefix_to_percent_dist.items():\n",
    "        amount = int(num_of_values * amount_percent)\n",
    "        my_index = insert_to_index_random(my_index, amount, prefix)\n",
    "\n",
    "    return my_index\n",
    "\n",
    "\n",
    "def insert_to_index_random(my_index, amount, prefix=''):\n",
    "    amount_in_iteration = min(CHUNKS_SIZE, amount)\n",
    "    print('generating %s values, chunk of %s, with prefix=\\'%s\\'' %(amount, amount_in_iteration, prefix))\n",
    "\n",
    "    proceed = 0\n",
    "    for i in range(0, amount, amount_in_iteration):\n",
    "        alphabet = list(ALPHABET)\n",
    "        np_alphabet = np.array(alphabet)\n",
    "        np_codes = np.random.choice(np_alphabet, [amount_in_iteration, KEY_LENGTH])\n",
    "        my_index.update({\n",
    "            prefix + ''.join(np_codes[i]): \"\".join(np_codes[i])\n",
    "            for i in range(len(np_codes))\n",
    "        })\n",
    "\n",
    "        proceed += amount_in_iteration\n",
    "        if (proceed % 150000) == 0:\n",
    "            print('done generating %s values' % (proceed))\n",
    "    return my_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-23 16:17:41.240747\n",
      "generating 1000000 values, chunk of 10000, with prefix='gggg'\n",
      "done generating 150000 values\n",
      "done generating 300000 values\n",
      "done generating 450000 values\n",
      "done generating 600000 values\n",
      "done generating 750000 values\n",
      "done generating 900000 values\n",
      "generating 600000 values, chunk of 10000, with prefix='hhhh'\n",
      "done generating 150000 values\n",
      "done generating 300000 values\n",
      "done generating 450000 values\n",
      "done generating 600000 values\n",
      "generating 400000 values, chunk of 10000, with prefix='mmmm'\n",
      "done generating 150000 values\n",
      "done generating 300000 values\n",
      "generating 120000 values, chunk of 10000, with prefix='rrrr'\n",
      "generating 1880000 values, chunk of 10000, with prefix=''\n",
      "done generating 150000 values\n",
      "done generating 300000 values\n",
      "done generating 450000 values\n",
      "done generating 600000 values\n",
      "done generating 750000 values\n",
      "done generating 900000 values\n",
      "done generating 1050000 values\n",
      "done generating 1200000 values\n",
      "done generating 1350000 values\n",
      "done generating 1500000 values\n",
      "done generating 1650000 values\n",
      "done generating 1800000 values\n",
      "2021-01-23 16:21:42.128463\n"
     ]
    }
   ],
   "source": [
    "prefix_to_percent = {\n",
    "    'gggg': 0.25,\n",
    "    'hhhh': 0.15,\n",
    "    'mmmm': 0.10,\n",
    "    'rrrr': 0.03,\n",
    "    '': 0.47\n",
    "}\n",
    "print(datetime.utcnow())\n",
    "num_of_values = 4_000_000\n",
    "my_index_4m = generate_btree_index_x_values_with_dist(num_of_values, prefix_to_percent, OOBTreeExtLean())\n",
    "print(datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-23 16:21:42.133014\n",
      "1\n",
      "2021-01-23 16:21:45.931630\n"
     ]
    }
   ],
   "source": [
    "print(datetime.utcnow())\n",
    "sampled = my_index_4m.random_sampling(k=10_000)\n",
    "print(datetime.utcnow()) # to 11 seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_prefix_ditribution(values):\n",
    "    return {value: occurences/len(values) for value, occurences in Counter([key[:4] for key in values]).most_common(10)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gggg': 0.2498,\n",
       " 'hhhh': 0.151,\n",
       " 'mmmm': 0.1015,\n",
       " 'rrrr': 0.0309,\n",
       " 'Xggt': 0.0002,\n",
       " 'SPyo': 0.0001,\n",
       " 'aLWR': 0.0001,\n",
       " 'CsCr': 0.0001,\n",
       " 'ZMRk': 0.0001,\n",
       " 'evjT': 0.0001}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_calculate_prefix_ditribution(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_index_4m."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
