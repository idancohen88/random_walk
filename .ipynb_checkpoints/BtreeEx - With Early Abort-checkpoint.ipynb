{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PURE_PYTHON=True\n"
     ]
    }
   ],
   "source": [
    "%env PURE_PYTHON True\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from BTrees.OOBTree import OOBTree\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import timeit\n",
    "\n",
    "CHUNKS_SIZE = 10000\n",
    "KEY_LENGTH = 8\n",
    "ALPHABET = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_debug_random_sampling = []\n",
    "DEFAULT_EXPLORING_STEP = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PURE_PYTHON\"] = \"True\"\n",
    "\n",
    "from BTrees.OOBTree import OOBTree as _OOBTree\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class OOBTreeExtLean(_OOBTree):\n",
    "    _fanout_distribution_cache = {}\n",
    "    _root = None\n",
    "    _cache_hit_counter = Counter()\n",
    "\n",
    "    def __init__(self):\n",
    "        super(OOBTreeExtLean, self).__init__()\n",
    "        self.walking_path_to_fanout_distribution = {}\n",
    "        self.default_exploring_step = DEFAULT_EXPLORING_STEP\n",
    "\n",
    "    def random_sampling(self, k):\n",
    "        self._first_walk_to_determine_root_coefs()\n",
    "        self.walking_path_to_fanout_distribution = {}\n",
    "        all_accept_reject_measures = {\n",
    "            'accept': [],\n",
    "            'reject': [],\n",
    "            'revisited_paths': Counter()\n",
    "        }\n",
    "\n",
    "        k = min(len(self), k)\n",
    "        sampled_values = []\n",
    "        all_walking_paths_set = set()\n",
    "        all_walking_paths_stats = []\n",
    "        while len(sampled_values) < k:\n",
    "            sampled_value, walking_path, walking_path_stats  = \\\n",
    "                self._get_value_and_path_by_random_walk_from_node(node=self)\n",
    "\n",
    "            if _this_value_was_sampled_already(walking_path, all_walking_paths_set):\n",
    "                all_accept_reject_measures['revisited_paths'][str(walking_path)] += 1\n",
    "                continue\n",
    "\n",
    "            accept_reject_measures = {\n",
    "                'path': walking_path,\n",
    "                'value': sampled_value,\n",
    "            }\n",
    "\n",
    "            all_accept_reject_measures['accept'].append(accept_reject_measures)\n",
    "\n",
    "            all_walking_paths_set.add(str(walking_path))\n",
    "            all_walking_paths_stats.append(walking_path_stats)\n",
    "            sampled_values.append(sampled_value)\n",
    "\n",
    "        add_to_debug_global(locals())\n",
    "\n",
    "        return sampled_values\n",
    "\n",
    "\n",
    "    def _calc_fanout_distribution_of_node(self, node):\n",
    "        if node in self._fanout_distribution_cache:\n",
    "            self._cache_hit_counter['hit'] += 1\n",
    "            return self._fanout_distribution_cache[node].copy()\n",
    "        self._cache_hit_counter['miss'] += 1\n",
    "\n",
    "        all_sizes = np.array([node.child.size for node in node._data])\n",
    "        node_distribution = all_sizes / sum(all_sizes)\n",
    "\n",
    "        self._fanout_distribution_cache[node] = node_distribution\n",
    "        return node_distribution.copy()\n",
    "\n",
    "    def _first_walk_to_determine_root_coefs(self):\n",
    "        self._root = self\n",
    "        branch_coefs = self._determine_root_to_leaf_walking_probs()\n",
    "        equations_matrix, equations_equal_matrix = self._create_equations_for_equaling_all_walking_probs(branch_coefs)\n",
    "\n",
    "        self.root_probs_coefs = np.linalg.solve(equations_matrix, equations_equal_matrix)\n",
    "\n",
    "    def _create_equations_for_equaling_all_walking_probs(self, branch_coefs):\n",
    "        root_fanout_distribution = self._calc_fanout_distribution_of_node(node=self)\n",
    "\n",
    "        equations_matrix = np.zeros((len(branch_coefs) + 1, len(branch_coefs)))\n",
    "        equations_equal_matrix = np.zeros(len(branch_coefs))\n",
    "\n",
    "        for root_child_number in range(len(branch_coefs)):\n",
    "            equations_matrix[root_child_number][0] = branch_coefs[0]\n",
    "            equations_matrix[root_child_number][root_child_number] = -1 * branch_coefs[root_child_number]\n",
    "            equations_matrix[-1][root_child_number] = root_fanout_distribution[root_child_number]\n",
    "\n",
    "        equations_matrix = equations_matrix[1:, ]\n",
    "\n",
    "        equations_equal_matrix[-1] = 1\n",
    "        return equations_matrix, equations_equal_matrix\n",
    "\n",
    "    def _determine_root_to_leaf_walking_probs(self):\n",
    "        assert self._root, 'must keep _root aside before working with this method'\n",
    "        root_to_leaf_walking_probs = {}\n",
    "        root_fanout_distribution = self._calc_fanout_distribution_of_node(self._root)\n",
    "\n",
    "        for root_child_number in range(len(self._root._data)):\n",
    "            current_node = self._root\n",
    "            walking_prob = root_fanout_distribution[root_child_number]\n",
    "            current_node = current_node._data[root_child_number].child\n",
    "\n",
    "            while not isinstance(current_node._data[DEFAULT_EXPLORING_STEP].child, self._bucket_type):\n",
    "                node_fanout_distribution = self._calc_fanout_distribution_of_node(current_node)\n",
    "                walking_prob *= node_fanout_distribution[0]\n",
    "                current_node = current_node._data[DEFAULT_EXPLORING_STEP].child\n",
    "\n",
    "            assert isinstance(current_node._data[DEFAULT_EXPLORING_STEP].child, self._bucket_type)\n",
    "            walking_prob *= 1 / len(current_node._data)\n",
    "            root_to_leaf_walking_probs[root_child_number] = walking_prob\n",
    "\n",
    "        branch_coefs = np.array(list(root_to_leaf_walking_probs.values()))\n",
    "        return branch_coefs\n",
    "\n",
    "    def _get_value_and_path_by_random_walk_from_node(self, node):\n",
    "        walking_path = []\n",
    "        current_node = node\n",
    "        prob_along_path = 1\n",
    "        walking_path_stats = []\n",
    "        while not isinstance(current_node, self._bucket_type):\n",
    "            next_random_step, chosen_random_step_prob = self._random_next_move_respect_fanout_prob(\n",
    "                current_node, walking_path)\n",
    "\n",
    "            prob_along_path *= chosen_random_step_prob\n",
    "            walking_path.append((next_random_step, current_node.size, chosen_random_step_prob, prob_along_path))\n",
    "            current_node = current_node._data[next_random_step].child\n",
    "            walking_path_stats.append({\n",
    "                'next_random_step': next_random_step,\n",
    "                'chosen_random_step_prob':\n",
    "                    chosen_random_step_prob, 'prob_along_path':prob_along_path})\n",
    "\n",
    "        next_random_step = np.random.randint(low=0, high=current_node.size)\n",
    "        chosen_random_step_prob = 1/current_node.max_leaf_size  # todo: size\n",
    "        prob_along_path *= chosen_random_step_prob\n",
    "        walking_path.append((next_random_step, current_node.size, chosen_random_step_prob, prob_along_path))\n",
    "        walking_path_stats.append({\n",
    "            'next_random_step': next_random_step,\n",
    "            'chosen_random_step_prob':\n",
    "                chosen_random_step_prob, 'prob_along_path': prob_along_path,\n",
    "            'entire_walking_path': walking_path})\n",
    "\n",
    "        leaf = current_node._keys\n",
    "        return leaf[next_random_step], walking_path, walking_path_stats\n",
    "\n",
    "    def _is_root_node(self, node):\n",
    "        assert self._root\n",
    "        return node == self._root\n",
    "\n",
    "    def _random_next_move_respect_fanout_prob(self, current_node, walking_path):\n",
    "        node_distribution = self._calc_fanout_distribution_of_node(current_node)\n",
    "        if self._is_root_node(current_node):\n",
    "            node_distribution *= self.root_probs_coefs\n",
    "            node_distribution = _fix_distribution_mistake_due_to_floating_calc_errors_if_needed(node_distribution)\n",
    "\n",
    "        next_random_step = np.random.choice(current_node.size, p=node_distribution)\n",
    "        \n",
    "        chosen_random_step_prob = node_distribution[next_random_step]\n",
    "        return next_random_step, chosen_random_step_prob\n",
    "\n",
    "\n",
    "    def join(self, right_tree):\n",
    "        pass\n",
    "\n",
    "\n",
    "def _fix_distribution_mistake_due_to_floating_calc_errors_if_needed(node_distribution):\n",
    "    # todo: as it happens only at the root, can fix the coefs\n",
    "    if sum(node_distribution) == 1:\n",
    "        return node_distribution\n",
    "\n",
    "    calc_error = 1 - sum(node_distribution)\n",
    "    assert calc_error <= 0.0_000_001, 'calculation faults cant be higher than this'\n",
    "    random_child = np.random.randint(len(node_distribution))\n",
    "    node_distribution[random_child] += calc_error\n",
    "    return node_distribution\n",
    "\n",
    "\n",
    "def add_to_debug_global(all_vars):\n",
    "    global _debug_random_sampling\n",
    "    _debug_random_sampling.append({\n",
    "        'params': {\n",
    "            'k': all_vars['k'],\n",
    "        },\n",
    "        'tree_size': len(all_vars['self']),\n",
    "        'all_accept_reject_measures': all_vars['all_accept_reject_measures'],\n",
    "        'all_walking_paths_stats': all_vars['all_walking_paths_stats']\n",
    "    })\n",
    "\n",
    "\n",
    "def _this_value_was_sampled_already(walking_path, all_walking_paths_set):\n",
    "    return str(walking_path) in all_walking_paths_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_btree_index_x_values_with_dist(num_of_values, disired_prefix_to_percent_dist, my_index=None):\n",
    "    my_index = my_index if my_index is not None else OOBTreeExt()\n",
    "    for prefix, amount_percent in disired_prefix_to_percent_dist.items():\n",
    "        amount = int(num_of_values * amount_percent)\n",
    "        my_index = insert_to_index_random(my_index, amount, prefix)\n",
    "\n",
    "    return my_index\n",
    "\n",
    "\n",
    "def insert_to_index_random(my_index, amount, prefix=''):\n",
    "    amount_in_iteration = min(CHUNKS_SIZE, amount)\n",
    "    print('generating %s values, chunk of %s, with prefix=\\'%s\\'' %(amount, amount_in_iteration, prefix))\n",
    "\n",
    "    proceed = 0\n",
    "    for i in range(0, amount, amount_in_iteration):\n",
    "        alphabet = list(ALPHABET)\n",
    "        np_alphabet = np.array(alphabet)\n",
    "        np_codes = np.random.choice(np_alphabet, [amount_in_iteration, KEY_LENGTH])\n",
    "        my_index.update({\n",
    "            prefix + ''.join(np_codes[i]): \"\".join(np_codes[i])\n",
    "            for i in range(len(np_codes))\n",
    "        })\n",
    "\n",
    "        proceed += amount_in_iteration\n",
    "        if (proceed % 150000) == 0:\n",
    "            print('done generating %s values' % (proceed))\n",
    "    return my_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_prefix_ditribution(values):\n",
    "    return {value: occurences/len(values) for value, occurences in Counter([key[:4] for key in values]).most_common(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-30 13:00:07.252999\n",
      "generating 1000000 values, chunk of 10000, with prefix='gggg'\n",
      "done generating 150000 values\n",
      "done generating 300000 values\n",
      "done generating 450000 values\n",
      "done generating 600000 values\n",
      "done generating 750000 values\n",
      "done generating 900000 values\n",
      "generating 600000 values, chunk of 10000, with prefix='hhhh'\n",
      "done generating 150000 values\n",
      "done generating 300000 values\n",
      "done generating 450000 values\n",
      "done generating 600000 values\n",
      "generating 400000 values, chunk of 10000, with prefix='mmmm'\n",
      "done generating 150000 values\n",
      "done generating 300000 values\n",
      "generating 120000 values, chunk of 10000, with prefix='rrrr'\n",
      "generating 1880000 values, chunk of 10000, with prefix=''\n",
      "done generating 150000 values\n",
      "done generating 300000 values\n",
      "done generating 450000 values\n",
      "done generating 600000 values\n",
      "done generating 750000 values\n",
      "done generating 900000 values\n",
      "done generating 1050000 values\n",
      "done generating 1200000 values\n",
      "done generating 1350000 values\n",
      "done generating 1500000 values\n",
      "done generating 1650000 values\n",
      "done generating 1800000 values\n",
      "2021-01-30 13:04:10.666064\n"
     ]
    }
   ],
   "source": [
    "prefix_to_percent = {\n",
    "    'gggg': 0.25,\n",
    "    'hhhh': 0.15,\n",
    "    'mmmm': 0.10,\n",
    "    'rrrr': 0.03,\n",
    "    '': 0.47\n",
    "}\n",
    "print(datetime.utcnow())\n",
    "num_of_values = 4_000_000\n",
    "my_index_4m = generate_btree_index_x_values_with_dist(num_of_values, prefix_to_percent, OOBTreeExtLean())\n",
    "print(datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-03 17:32:41.589325\n",
      "2021-02-03 17:32:45.564131\n"
     ]
    }
   ],
   "source": [
    "print(datetime.utcnow())\n",
    "sampled = my_index_4m.random_sampling(k=10_000)\n",
    "print(datetime.utcnow()) # to 11 seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tree_elements = list(my_index_4m.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.01210924999999996, pvalue=0.1064102220731521)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.kstest(sampled, all_tree_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tree_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
